前言：
这是机器学习的一次作业，线性核与高斯核的SVM和决策树及随机森林的比较。

## 概述

选择室内定位的数据集，分别用线性核和高斯核训练一个SVM，并与决策树、随机森林进行实验比较，分析准确率、收敛速度以及泛化能力，并对收敛速度进行可视化绘图。

## 代码实现

**1.数据集的读取及预处理**

我选择了UCI的室内定位数据集，使用了urllib库从https://archive.ics.uci.edu/ml/machine-learning-databases/00422/wifi_localization.txt中下载数据库并读取。注意读取的为txt文件，数据间的分隔符号为"\t"。

随后对数据集进行预处理，按照4:1的比例划分训练集与测试集。

```python
import pandas as pd
import numpy as np
import urllib.request
from sklearn.model_selection import train_test_split

url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00422/wifi_localization.txt'
filename = 'wifi_localization.txt'
urllib.request.urlretrieve(url, filename)

data = pd.read_csv('wifi_localization.txt', sep='\t', header=None) # 读取数据

X = data.iloc[:, :-1].values
y = data.iloc[:, -1].values

# 划分训练集和测试集
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
```

**2.四种算法的实现与准确率的计算**

此次作业中的算法直接调用sklearn中封装好的函数。因此四种算法的代码实现近乎类似，其中的参数均采用默认参数。准确率的计算直接采用accuracy_score函数来实现。SVC中的kernel参数为'linear'时代表使用线性核，为'rbf'时代表使用高斯核。下面是代码实现。

```python
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

# SVM（线性核）
svm_linear = SVC(kernel='linear', C=1)
svm_linear.fit(X_train, y_train)
svm_linear_pred = svm_linear.predict(X_test)
svm_linear_acc = accuracy_score(y_test, svm_linear_pred)

# SVM（高斯核）
svm_rbf = SVC(kernel='rbf', C=1)
svm_rbf.fit(X_train, y_train)
svm_rbf_pred = svm_rbf.predict(X_test)
svm_rbf_acc = accuracy_score(y_test, svm_rbf_pred)

# 决策树
dt = DecisionTreeClassifier()
dt.fit(X_train, y_train)
dt_pred = dt.predict(X_test)
dt_acc = accuracy_score(y_test, dt_pred)

# 随机森林
rf = RandomForestClassifier()
rf.fit(X_train, y_train)
rf_pred = rf.predict(X_test)
rf_acc = accuracy_score(y_test, rf_pred)

# 打印结果
print("SVM（线性核）准确率：", svm_linear_acc)
print("SVM（高斯核）准确率：", svm_rbf_acc)
print("决策树准确率：", dt_acc)
print("随机森林准确率：", rf_acc)
```

得到的结果为：

SVM（线性核）准确率： 0.9775

SVM（高斯核）准确率： 0.98

决策树准确率： 0.975

随机森林准确率： 0.9825

**3.收敛速度可视化与比较**

随着训练集规模的增大，训练集与测试集得分的变化存在一定趋势，这个变化的速度便可以反应不同算法的收敛速度。于是用matplotlib.pyplot库将四种算法的收敛速度示意图分别绘制出来。代码如下：

```python
# 训练集大小列表
train_sizes = np.linspace(0.001, 1.0, 100) # 从0.001到1.0，分成100份

# 用learning_curve函数计算训练集和验证集上的得分
train_sizes_dt, train_scores_dt, validation_scores_dt = learning_curve(estimator=dt, X=X_train, y=y_train, train_sizes=train_sizes, cv=5)
train_sizes_rf, train_scores_rf, validation_scores_rf = learning_curve(estimator=rf, X=X_train, y=y_train, train_sizes=train_sizes, cv=5)
train_sizes_svm_linear, train_scores_svm_linear, validation_scores_svm_linear = learning_curve(estimator=svm_linear, X=X_train, y=y_train, train_sizes=train_sizes, cv=5)
train_sizes_svm_rbf, train_scores_svm_rbf, validation_scores_svm_rbf = learning_curve(estimator=svm_rbf, X=X_train, y=y_train, train_sizes=train_sizes, cv=5)

# 计算每种算法的平均训练得分和验证得分
train_scores_mean_svm_linear = np.mean(train_scores_svm_linear, axis=1) 
validation_scores_mean_svm_linear = np.mean(validation_scores_svm_linear, axis=1)
train_scores_mean_svm_rbf = np.mean(train_scores_svm_rbf, axis=1)
validation_scores_mean_svm_rbf = np.mean(validation_scores_svm_rbf, axis=1)
train_scores_mean_dt = np.mean(train_scores_dt, axis=1)
validation_scores_mean_dt = np.mean(validation_scores_dt, axis=1)
train_scores_mean_rf = np.mean(train_scores_rf, axis=1)
validation_scores_mean_rf = np.mean(validation_scores_rf, axis=1)

# 绘制学习曲线(SVM Linear)
plt.plot(train_sizes_svm_linear, train_scores_mean_svm_linear, label='Training score (SVM Linear)')
plt.plot(train_sizes_svm_linear, validation_scores_mean_svm_linear, label='Validation score (SVM Linear)')

# 添加图例和标签(SVM Linear)
plt.legend()
plt.xlabel('Training Set Size')
plt.ylabel('Accuracy')
plt.title('Learning Curves(SVM Linear)')
plt.show()

# 绘制学习曲线(SVM RBF)
plt.plot(train_sizes_svm_rbf, train_scores_mean_svm_rbf, label='Training score (SVM RBF)')
plt.plot(train_sizes_svm_rbf, validation_scores_mean_svm_rbf, label='Validation score (SVM RBF)')

# 添加图例和标签(SVM RBF)
plt.legend()
plt.xlabel('Training Set Size')
plt.ylabel('Accuracy')
plt.title('Learning Curves(SVM RBF)')
plt.show()

# 绘制学习曲线(Decision Tree)
plt.plot(train_sizes_dt, train_scores_mean_dt, label='Training score (Decision Tree)')
plt.plot(train_sizes_dt, validation_scores_mean_dt, label='Validation score (Decision Tree)')

# 添加图例和标签(Decision Tree)
plt.legend()
plt.xlabel('Training Set Size')
plt.ylabel('Accuracy')
plt.title('Learning Curves(Decison Tree)')
plt.show()

# 绘制学习曲线(Random Forest)
plt.plot(train_sizes_rf, train_scores_mean_rf, label='Training score (Random Forest)')
plt.plot(train_sizes_rf, validation_scores_mean_rf, label='Validation score (Random Forest)')   

# 添加图例和标签(Random Forest)
plt.legend()
plt.xlabel('Training Set Size')
plt.ylabel('Accuracy')
plt.title('Learning Curves(Random Forest)')
plt.show()
```

得到的四张图分别如下：

## 结果分析与比较

从准确率的输出可以看到，四种算法的准确率差别不大，均比较高，都在0.97以上，其中随机森林的准确率最高。

从收敛速度来看，高斯核SVM、决策树、随机森林的收敛速度相差不大，均在几十个数据左右达到最优，且能维持稳定。而线性核SVM收敛速度也很快，但是达到最大值后准确率便上下波动，说明存在一定的过拟合。

从泛化能力来看，除了线性核SVM之外，准确率达到最大之后均大致保持稳定，说明不存在过拟合。而线性核的准确率上下波动，过拟合现象明显，泛化能力较弱。

除此之外，我分别用这几种算法训练模型，发现随机森林所需要的时间最长，远大于其他三种算法，说明随机森林虽然准确率最高，但是消耗时间较长。



综合收敛速度、泛化能力、训练速度来看，采用高斯核或决策树更方便合理。